{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jasonola/spacy/blob/master/Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr_D456Wu-9r"
   },
   "source": [
    "> Notes : \n",
    "\n",
    "\n",
    "*   Les instructions pour commenter votre code sont sur le moodle du cours, dans la section \"Commenter du code\".\n",
    "*   Pour installer des librairies dans le colab, utilisez la commande \n",
    "\n",
    "\n",
    "```\n",
    "!pip install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "78QrmsKvlU2K"
   },
   "source": [
    "a) Téléchargez la liste de romans en .txt présente ici https://drive.switch.ch/index.php/s/b5j3otbaWiaymZ4. Pour information, les originaux en .xml sont également disponibles, ainsi que le script de conversion `xml_book_parser`. \n",
    "\n",
    "> De cette manière, s'il y a des changements à opérer dans la conversion (et le traitement des espaces, notamment), vous pourrez toujours refaire l'opération.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOgS0EnEmXcA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Rkvf80oTfl2"
   },
   "source": [
    "b) Le code présent dans le colab  [Spacy_pipeline](https://colab.research.google.com/drive/1knexo5mQqH9bLstERYefwNx0JtV45qt0) sert à identifier les personnages d'un roman et toutes leurs occurrences à l'aide de Spacy. \n",
    "*   La fonction `spacy_char_pipe` prend en input un roman en .txt où chaque ligne est un paragraphe, et enregistre un fichier json contenant la liste de tous les personnages triée par nombre d'occurrences, et la liste des paragraphes contenant ces occurrences.\n",
    "*   La fonction `spacy_df_pipe` prend en input un roman en .txt où chaque ligne est un paragraphe, et enregistre un fichier .csv contenant un dataframe à cinq colonnes (name, start_pos, end_pos, tag, score) où chaque ligne est une occurrence d'entité nommée reconnue par Spacy. \n",
    "\n",
    "Documentez chacune des fonctions présentes dans le colab (à la manière de la documentation de DHTK, par exemple ici https://gitlab.com/dhtk/dhtk/-/blob/testing/dhtk/common/book.py) pour vous assurer d'avoir bien compris le rôle de chacune d'entre elles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TNErio4oiVZ"
   },
   "source": [
    "c) A l'aide de la librairie Python `dataclasses` (https://docs.python.org/3/library/dataclasses.html), transformez le code fonctionnel présent dans le colab \"Spacy_pipeline\" en un code orienté objet. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> Vous pouvez trouver des tutoriels en ligne pour comprendre les data classes, par exemple ici : http://zetcode.com/python/dataclass/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "eAM00Et9L6VI",
    "outputId": "c346c603-f28a-4abd-b813-107bf7e5a50a"
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg  #download the spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gNDYoO6Lz8k"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.symbols import nsubj, VERB\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "import pandas\n",
    "from dataclasses import dataclass\n",
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gNDYoO6Lz8k"
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "# c'est une librairie qui permet de demander un fichier a l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root=tk.Tk()\n",
    "root.withdraw()\n",
    "# je sais pas trop ce que c est mais c'est necessaire pour demander le fichier,\n",
    "# je pense c'est une instance de fenetre mais pas sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jasonola/Desktop/spacy/textes/KingdomoftheBlindbyEPhillipsEdwardPhillipsOppenhei1442.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_path = filedialog.askopenfilename()\n",
    "root.update() # faut utiliser ca apparement pour pas que la fenetre parte sur une boucle infinie\n",
    "book_path\n",
    "# la j'utilise le tkinter, donc il va prompt une fenetre qui demandera quel fichier tu veux et il retourne le chemin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "2qhDG6xOMeMM",
    "outputId": "dc650d8b-7089-456f-921a-a375d716dd36"
   },
   "outputs": [],
   "source": [
    "with open(book_path,\"r\") as f:\n",
    "    book = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGMnBZHHMxW7"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")  # load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsxEheR_YhWZ"
   },
   "outputs": [],
   "source": [
    "#Insérer votre code ici\n",
    "# Classe principale Book\n",
    "@dataclass\n",
    "class Book:\n",
    "  path:str\n",
    "  def get_name(self):\n",
    "    \"\"\"Getting the name of the book between the '/'and the '.'\"\"\"\n",
    "    name = self.path.split('/')[-1]\n",
    "    name = name.split('.')[0]\n",
    "    return name\n",
    "  def get_lines(self):\n",
    "    with open(self.path, 'r', encoding='utf-8', newline='\\n') as file:\n",
    "        content = file.read()\n",
    "        lines = content.split('\\n')\n",
    "        return lines\n",
    "  def spacy_ner(self):\n",
    "    paragraphs = []\n",
    "    len_diffs = []\n",
    "    for line in tqdm(self.get_lines()):\n",
    "        line_length = len(line)\n",
    "        paragraph = Line.spacy_tag(line) \n",
    "        len_diff = line_length - len(paragraph.text)\n",
    "        paragraphs.append(paragraph)\n",
    "        len_diffs.append(len_diff)    \n",
    "    return paragraphs, len_diffs\n",
    "  def spacy_char_pipe(self):\n",
    "    name = self.get_name()\n",
    "    \n",
    "    paragraphs, _ = self.spacy_ner()\n",
    "    test = Character(paragraphs)\n",
    "    characters_sorted, context = test.spacy_characters(paragraphs)\n",
    "    json_char = {'counter': characters_sorted, 'context': str(context)}\n",
    "        \n",
    "    with open(f'./Data/{name}_characters_spacy.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(json_char, file)\n",
    "                  \n",
    "    return characters_sorted, context\n",
    "  def spacy_df_pipe(self):\n",
    "    entities = []\n",
    "    offset = 0\n",
    "    \n",
    "    paragraphs, len_diffs = self.spacy_ner()\n",
    "    \n",
    "    for i in range(len(paragraphs)):\n",
    "        paragraph = paragraphs[i]\n",
    "        len_diff = len_diffs[i]\n",
    "        for ent in paragraph.ents:\n",
    "\n",
    "            entity = {\n",
    "                'name': ent.text, \n",
    "                'start_pos': offset + ent.start_char, \n",
    "                'end_pos': offset + ent.end_char, \n",
    "                'tag': ent.label_, \n",
    "                'score': 1, \n",
    "            }\n",
    "\n",
    "            entities.append(entity)\n",
    "\n",
    "        offset += len(paragraph.text) + len_diff + 1\n",
    "\n",
    "    entity_df = pandas.DataFrame(entities)\n",
    "\n",
    "    name = self.get_name()\n",
    "    entity_df.to_csv(f'./Data/{name}_spacy.csv')\n",
    "    \n",
    "    return entity_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_JfHtDgl2RN"
   },
   "outputs": [],
   "source": [
    "# spacy_tag dans une autre classe qu'on appele depuis spacy_ner dans la classe Book !\n",
    "@dataclass\n",
    "class Line:\n",
    "  def spacy_tag(self):\n",
    "    paragraph = nlp(self)\n",
    "    return paragraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8BFlF9KsYZk-"
   },
   "outputs": [],
   "source": [
    "#Classe Character\n",
    "@dataclass\n",
    "# Determine if the entity is a person\n",
    "class Character:\n",
    "\n",
    "  def __init__(self, paragraphs):\n",
    "    self.paragraphs = paragraphs\n",
    "\n",
    "  def is_char(self, entity):\n",
    "    return entity.label == 'PERSON'\n",
    "\n",
    "  def count_char(self, paragraph):\n",
    "    nb_char_par = Counter()\n",
    "\n",
    "    for entity in paragraph.ents:\n",
    "      if self.is_char(entity):\n",
    "        nb_char_par[entity.text] += 1\n",
    "\n",
    "    return nb_char_par\n",
    "\n",
    "  def sort_char(self, char_list):\n",
    "    characters_sorted = char_list.most_common()\n",
    "    return characters_sorted\n",
    "\n",
    "  def spacy_characters(self, paragraphs):\n",
    "    nb_characters = Counter()\n",
    "    context = defaultdict(list)\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "      nb_char_par = self.count_char(paragraph)\n",
    "      nb_characters.update(nb_char_par)\n",
    "      for entity in nb_char_par:\n",
    "        context[entity].append(paragraph)\n",
    "\n",
    "    characters_sorted = self.sort_char(nb_characters)\n",
    "    return characters_sorted, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "S6YAHU9pPKvA",
    "outputId": "d3d16364-e85e-404e-ad3d-b6b2e77ff0f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2268/2268 [00:20<00:00, 110.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lady Anselman</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the Ritz Hotel</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>French</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>NORP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>French</td>\n",
       "      <td>247</td>\n",
       "      <td>253</td>\n",
       "      <td>NORP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabinet</td>\n",
       "      <td>390</td>\n",
       "      <td>397</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>Geraldine?”he</td>\n",
       "      <td>388628</td>\n",
       "      <td>388641</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>these days</td>\n",
       "      <td>388853</td>\n",
       "      <td>388863</td>\n",
       "      <td>DATE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>Hugh</td>\n",
       "      <td>388962</td>\n",
       "      <td>388966</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>dear,”he</td>\n",
       "      <td>389051</td>\n",
       "      <td>389059</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>Lady Anselman '</td>\n",
       "      <td>389145</td>\n",
       "      <td>389160</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3234 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  start_pos  end_pos     tag  score\n",
       "0       Lady Anselman          0       13  PERSON      1\n",
       "1      the Ritz Hotel         51       65     ORG      1\n",
       "2              French        146      152    NORP      1\n",
       "3              French        247      253    NORP      1\n",
       "4             Cabinet        390      397     ORG      1\n",
       "...               ...        ...      ...     ...    ...\n",
       "3229    Geraldine?”he     388628   388641  PERSON      1\n",
       "3230       these days     388853   388863    DATE      1\n",
       "3231             Hugh     388962   388966  PERSON      1\n",
       "3232         dear,”he     389051   389059     ORG      1\n",
       "3233  Lady Anselman '     389145   389160  PERSON      1\n",
       "\n",
       "[3234 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests of methods, je fais chaque methode l'une apres l'autre il y a des methodes \n",
    "# qui demandent d'autres methodes genre spacy_ner qui demande spacy_tag, enlevez juste le # devant un et run\n",
    "p = Book(book_path)\n",
    "#p.get_name() # Works !\n",
    "#p.get_lines() # Works !\n",
    "#p.spacy_ner() # Works !!!\n",
    "\n",
    "\n",
    "#paragraphs, _ = p.spacy_ner()\n",
    "#test = Character(paragraphs)\n",
    "#test.spacy_characters()\n",
    "#p.spacy_char_pipe() # ca marche mais ca retourne une liste vide\n",
    "p.spacy_df_pipe() # ca marche quand je commente la partie .to_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "5yNochR0NZra",
    "outputId": "0e8aef60-bad7-4b2b-e40a-e243ff81841d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mText  :  Main Noun  :  Dependency  :  Completed object\u001b[0m\n",
      "This text | text | nsubj | serves \n",
      "\n",
      "\u001b[1mText  :  Main Noun  :  Dependency  :  Completed object\u001b[0m\n",
      "a very nice exemple | exemple | pobj | as \n",
      "\n",
      "\u001b[1mText  :  Main Noun  :  Dependency  :  Completed object\u001b[0m\n",
      "And this part | part | ROOT | part \n",
      "\n",
      "\u001b[1mText  :  Main Noun  :  Dependency  :  Completed object\u001b[0m\n",
      "the text | text | pobj | of \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Insérer votre code ici\n",
    "\n",
    "exemple_string = nlp(\"This text serves as a very nice exemple. And this part of the text too\")\n",
    "\n",
    "\n",
    "# Code pour utiliser un texte importé\n",
    "#chemin = \"/content/AHorsesTalebyMarkTwain1086.txt\"\n",
    "#with open(chemin, \"r\") as f:\n",
    "  #my_book = f.read()\n",
    "  #text_exemple = nlp(my_book)\n",
    "\n",
    "# Ces deux variables permettent de mettre du texte en gras\n",
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'\n",
    "\n",
    "@dataclass\n",
    "class SpacyFeatures:\n",
    "  # Affichage des POS tag\n",
    "  def get_tag(self):\n",
    "    for token in self:\n",
    "      print(BOLD + \"Text  :  Type  :  children\" + END)\n",
    "      print(f\"{token.text} | {token.pos_} | {[child for child in token.children]} \\n\")\n",
    "  # Affichage des noun chunks et des dépendences \n",
    "  def noun_chunk(self):\n",
    "    for chunk in self.noun_chunks:\n",
    "      print(BOLD + \"Text  :  Main Noun  :  Dependency  :  Completed object\" + END)\n",
    "      print(f\"{chunk.text} | {chunk.root.text} | {chunk.root.dep_} | {chunk.root.head.text} \\n\")\n",
    "  #Affichage de verbes\n",
    "  def get_verbs(self):\n",
    "    verbs = set()\n",
    "    for possible_subject in self:\n",
    "      if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        verbs.add(possible_subject.head)\n",
    "    print(verbs)\n",
    "\n",
    "  #Affichage du parsing tree\n",
    "  def parsing_tree(self):\n",
    "    displacy.render(self, style='dep', jupyter=True, options={'distance': 130})\n",
    "    displacy.render(self, style='ent', jupyter=True)\n",
    "  \n",
    "  #Séparateur de phrases\n",
    "  def get_sentence(self):\n",
    "    for sent in self.sents:\n",
    "      print(sent.text)\n",
    "\n",
    "  #Trouver des entités nommées, des phrases et des concepts\n",
    "  def get_entity(self):\n",
    "    for entity in self.ents:\n",
    "      print(entity.text, entity.label_)\n",
    "\n",
    "SpacyFeatures.noun_chunk(exemple_string)\n",
    "#SpacyFeatures.parsing_tree(exemple_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4CayJGXen2LM"
   },
   "source": [
    "d) A l'aide de la librairie Spacy https://spacy.io/, intégrez les autres fonctions disponible dans Spacy  (comme montré [ici](https://spacy.io/usage/linguistic-features))  dans la classe que vous avez créée au point *b)*\n",
    "\n",
    "\n",
    "> Pour installer Spacy : suivre les consignes présentes sur ce lien https://spacy.io/usage.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Spacy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
